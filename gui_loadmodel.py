# -*- coding: utf-8 -*-
"""test_unet10_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uob03iWx65nuIsw948-bTzPVFryEUh38
"""



# kết nối gg drive với colab
# from google.colab import drive
#
# drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import os
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

plt.style.use("ggplot")
# %matplotlib inline
from tkinter import *
from tkinter import filedialog
from PIL import  Image,ImageTk
import cv2
# from tqdm import tqdm_notebook, tnrange
from glob import glob
from itertools import chain
from skimage.io import imread, imshow, concatenate_images
from skimage.transform import resize
from skimage.morphology import label
from sklearn.model_selection import train_test_split
from keras.optimizers import adam_v2
import tensorflow as tf
from skimage.color import rgb2gray
from keras import Input
from keras.models import Model, load_model, save_model
from keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, \
    MaxPooling2D, concatenate


from keras.callbacks import EarlyStopping, ModelCheckpoint

from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint

# Set Parameters
im_width = 256
im_height = 256

# đọc dữ liệu  image's path và mask's path
train_files = []
mask_files = glob(r'C:\Users\truon\PycharmProjects\mri_nao\dataset\lgg-mri-segmentation\kaggle_3m/*/*_mask*')

for i in mask_files:
    train_files.append(i.replace('_mask', ''))

print(train_files[:10])
print(mask_files[:10])

# show một số ví dụ
# rows, cols = 3, 3
# fig = plt.figure(figsize=(10, 10))  # tạo biểu đồ
# for i in range(1, rows * cols + 1):
#     fig.add_subplot(rows, cols, i)  # tạo thêm sub-plot vị trí tiếp
#     img_path = train_files[i]  # lấy path dữ liệu
#     msk_path = mask_files[i]
#     img = cv2.imread(img_path)  # đọc ảnh
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     msk = cv2.imread(msk_path)
#     plt.imshow(img)
#     plt.imshow(msk, alpha=0.4)
# plt.show()

# phân chia dữ liệu để train,test,val
df = pd.DataFrame(data={"filename": train_files, 'mask': mask_files})
df_train, df_test = train_test_split(df, test_size=0.1)
df_train, df_val = train_test_split(df_train, test_size=0.2)

print("số data train", df_train.values.shape)
print("số data vali", df_val.values.shape)
print("số data test", df_test.values.shape)


# tăng cường dữ liệu trước khi train
def train_generator(data_frame, batch_size, aug_dict,
                    image_color_mode="rgb",
                    mask_color_mode="grayscale",
                    image_save_prefix="image",
                    mask_save_prefix="mask",
                    save_to_dir=None,
                    target_size=(256, 256),
                    seed=1):
    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)

    image_generator = image_datagen.flow_from_dataframe(
        data_frame,
        x_col="filename",
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed)

    mask_generator = mask_datagen.flow_from_dataframe(
        data_frame,
        x_col="mask",
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed)

    train_gen = zip(image_generator, mask_generator)

    for (img, mask) in train_gen:
        img, mask = adjust_data(img, mask)
        yield (img, mask)


def adjust_data(img, mask):
    img = img / 255
    mask = mask / 255
    mask[mask > 0.5] = 1
    mask[mask <= 0.5] = 0
    return (img, mask)


# định nghĩa hàm mất mát iou dice similarity coefficient(hệ số tương đương)
smooth = 100


def dice_coef(y_true, y_pred):
    y_truef = K.flatten(y_true)
    y_predf = K.flatten(y_pred)
    And = K.sum(y_truef * y_predf)
    return ((2 * And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))


def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)


def iou(y_true, y_pred):
    intersection = K.sum(y_true * y_pred)
    sum_ = K.sum(y_true + y_pred)
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return jac


def jac_distance(y_true, y_pred):
    y_truef = K.flatten(y_true)
    y_predf = K.flatten(y_pred)

    return - iou(y_true, y_pred)


# định nghĩa mạng unet
def unet(input_size=(256, 256, 3)):
    inputs = Input(input_size)
    # bên encoder
    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)
    bn1 = Activation('relu')(conv1)
    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)
    bn1 = BatchNormalization(axis=3)(conv1)
    bn1 = Activation('relu')(bn1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)

    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)
    bn2 = Activation('relu')(conv2)
    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)
    bn2 = BatchNormalization(axis=3)(conv2)
    bn2 = Activation('relu')(bn2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)

    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)
    bn3 = Activation('relu')(conv3)
    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)
    bn3 = BatchNormalization(axis=3)(conv3)
    bn3 = Activation('relu')(bn3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)

    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)
    bn4 = Activation('relu')(conv4)
    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)
    bn4 = BatchNormalization(axis=3)(conv4)
    bn4 = Activation('relu')(bn4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)

    # trung gian

    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)
    bn5 = Activation('relu')(conv5)
    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)
    bn5 = BatchNormalization(axis=3)(conv5)
    bn5 = Activation('relu')(bn5)

    # bên encoder
    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)
    conv6 = Conv2D(512, (3, 3), padding='same')(up6)
    bn6 = Activation('relu')(conv6)
    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)
    bn6 = BatchNormalization(axis=3)(conv6)
    bn6 = Activation('relu')(bn6)

    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)
    conv7 = Conv2D(256, (3, 3), padding='same')(up7)
    bn7 = Activation('relu')(conv7)
    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)
    bn7 = BatchNormalization(axis=3)(conv7)
    bn7 = Activation('relu')(bn7)

    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)
    conv8 = Conv2D(128, (3, 3), padding='same')(up8)
    bn8 = Activation('relu')(conv8)
    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)
    bn8 = BatchNormalization(axis=3)(conv8)
    bn8 = Activation('relu')(bn8)

    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)
    conv9 = Conv2D(64, (3, 3), padding='same')(up9)
    bn9 = Activation('relu')(conv9)
    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)
    bn9 = BatchNormalization(axis=3)(conv9)
    bn9 = Activation('relu')(bn9)

    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)

    return Model(inputs=[inputs], outputs=[conv10])


model = unet()
model.summary()

# training
EPOCHS = 150
BATCH_SIZE = 32
learning_rate = 1e-4
# xoay,lật,scale
train_generator_args = dict(rotation_range=0.2,
                            width_shift_range=0.05,
                            height_shift_range=0.05,
                            shear_range=0.05,
                            zoom_range=0.05,
                            horizontal_flip=True,
                            fill_mode='nearest')
train_gen = train_generator(df_train, BATCH_SIZE,
                            train_generator_args,
                            target_size=(im_height, im_width))

test_gener = train_generator(df_val, BATCH_SIZE,
                             dict(),
                             target_size=(im_height, im_width))

model = unet(input_size=(im_height, im_width, 3))

opt = tf.keras.optimizers.Adam(learning_rate)
model.compile(optimizer=opt, loss=dice_coef_loss, metrics=["binary_accuracy", iou, dice_coef])

# callbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]
#
# history = model.fit(train_gen,
#                     steps_per_epoch=len(df_train) / BATCH_SIZE,
#                     epochs=EPOCHS,
#                     callbacks=callbacks,
#                     validation_data=test_gener,
#                     validation_steps=len(df_val) / BATCH_SIZE)

# test data
# vẽ biểu đồ nhận xét
# a = history.history
#
# list_traindice = a['dice_coef']
# list_testdice = a['val_dice_coef']
#
# list_trainjaccard = a['iou']
# list_testjaccard = a['val_iou']
#
# list_trainloss = a['loss']
# list_testloss = a['val_loss']
# plt.figure(1)
# plt.plot(list_testloss, 'b-')
# plt.plot(list_trainloss, 'r-')
# plt.xlabel('iteration')
# plt.ylabel('loss')
# plt.title('loss graph', fontsize=15)
# plt.figure(2)
# plt.plot(list_traindice, 'r-')
# plt.plot(list_testdice, 'b-')
# plt.xlabel('iteration')
# plt.ylabel('accuracy')
# plt.title('accuracy graph', fontsize=15)
# plt.show()

# load modle
model = load_model('unet_brain_mri_seg123.hdf5',
                   custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})

# test_gen = train_generator(df_test, BATCH_SIZE,
#                            dict(),
#                            target_size=(im_height, im_width))
# # đánh giá dữ liệu trên tập df_test
# results = model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)
# print("Test lost: ", results[0])
# print("Test IOU: ", results[1])
# print("Test Dice Coefficent: ", results[2])
import tkinter as tk
from tkinter.messagebox import showinfo
from tkinter import ttk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
root = tk.Tk()
root.title("GUI KẾT QUẢ PREDICT")
root.geometry("950x450")

def openfile():
    filetypes = (
        ('All files', '*.*'),
        ('text files', '*.txt')

    )

    filename = filedialog.askopenfilename(
        title='Open a file',
        initialdir='/',
        filetypes=filetypes)

    showinfo(
        title=' FILE ĐÃ CHỌN',
        message=filename
    )
    filemask = filename.replace(".","_mask.")
    img = cv2.imread(filename)
    img = cv2.resize(img, (im_height, im_width))
    img = img / 255
    img = img[np.newaxis, :, :, :]
    pred = model.predict(img)

    fig = plt.figure(figsize=(7, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(np.squeeze(img))
    plt.title(' ẢNH MRI GỐC')
    plt.subplot(1, 3, 2)
    plt.imshow(np.squeeze(cv2.imread(filemask)))
    plt.title('ẢNH MRI Mask')
    plt.subplot(1, 3, 3)
    plt.imshow(np.squeeze(pred) > .5)
    plt.title('VÙNG LỖI DỰ ĐOÁN')

    canvas = FigureCanvasTkAgg(fig)  # creating the Tkinter canvas containing the Matplotlib figure
    canvas.draw()
    canvas.get_tk_widget().place(x=20, y=80)
plot_lable =Label(root, text = "_____MÔ HÌNH NHẬN DẠNG ĐIỂM BẤT THƯỜNG TRÊN NÃO QUA HÌNH ẢNH CHỤP MRI_____").place(x=100, y=20)
plot_button = tk.Button( command=openfile, height=2, width=10, text="CHỌN ẢNH").place(x=120, y=40)

root.mainloop()

